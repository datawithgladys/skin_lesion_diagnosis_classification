{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook runs on AWS 'g4dn.4xlarge' EC2 instance with Ubuntu's Deep Learning AMI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Skin Lesion Classification and Diagnosis\n",
    "## Notebook 3b: Oversampling by SMOTE (Diagnosis Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like what we have done in notebook 3a, we will be executing Synthetic Minority Oversampling Technique (SMOTE) on our highly imbalanced 3-classes image dataset (for diagnosis classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "- [Problem Statement](#Problem-Statement)\n",
    "- [Background Information on SMOTE](#Background-Information-on-SMOTE)\n",
    "- [Importing Libraries](#Importing-Libraries)\n",
    "- [Loading Data](#Loading-Data)\n",
    "- [Train-Test-Validation Split](#Train-Test-Validation-Split)\n",
    "- [Executing SMOTE](#Executing-SMOTE)\n",
    "- [Exporting Data](#Exporting-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Skin cancer is the most common cancer globally, with melanoma being the most deadly form. Even though dermoscopy, a skin imaging modality, has demonstrated improvement for the diagnosis of skin cancer compared to unaided visual inspection<sup>[[1]](https://challenge2019.isic-archive.com/)</sup>, numerous cases of benign lesions are still being diagnosed as malicious and vice versa<sup>[[2]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6394090/)</sup>. Every year, poor diagnostic errors adds an estimated $673 million in overall cost to manage the disease<sup>[[3]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543387/)</sup>.\n",
    "\n",
    "In this project, we aim to improve the diagnostic rate of skin cancer through the classification of skin lesions for dermatologists working at hospitals or skin cancer clinics in Singapore, who will need experience or expertise in diagnosing skin cancer before they can accurately identify and diagnose lesions upon visual and dermoscopy inspection<sup>[[3]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543387/)</sup>. This will be done through the classification of skin lesion dermoscopy images, in which we will predict two important tasks through the usage of Convolutional Neural Network models: <br>\n",
    "1. a specific skin lesion diagnosis, and <br>\n",
    "2. whether the lesion is malignant, benign, or pre-cancerous. <br>\n",
    "\n",
    "The model will be evaluated based on its accuracy, followed by its recall rate since we are looking to minimise false negatives. Ultimately, we aim to get as close to a real evaluation of a dermatologist as possible: predicting the type of skin lesion; and whether the lesion is malignant, pre-cancerous or benign from dermoscopy images. With our models, we hope to aid dermatologists in their decision-making process of diagnosing skin lesions, hence allowing them to improve their diagnostic accuracy and come up with appropriate treatments for patients with skin lesions and/or cancers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background information on SMOTE\n",
    "SMOTE is an oversampling technique that generates synthetic samples for the minority classes, which helps to overcome the overfitting problem that can potentially arise from random oversampling. It focuses on the feature space to generate new instances with the help of interpolation between the positive instances that lie together<sup>[[5]](https://www.analyticsvidhya.com/blog/2020/10/overcoming-class-imbalance-using-smote-techniques/)</sup>. In the case of SMOTE, k-nearest neighbours is used to interpolate new synthetic instances for the minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in labeled_ground_truth\n",
    "all_labels = pd.read_csv('../datasets/labeled_ground_truth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>mel</th>\n",
       "      <th>nv</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "      <th>bkl</th>\n",
       "      <th>df</th>\n",
       "      <th>vasc</th>\n",
       "      <th>lesion</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign</th>\n",
       "      <th>malignant</th>\n",
       "      <th>precancerous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DERM_001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>df</td>\n",
       "      <td>benign</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DERM_002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>df</td>\n",
       "      <td>benign</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DERM_003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>df</td>\n",
       "      <td>benign</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DERM_004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>df</td>\n",
       "      <td>benign</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DERM_005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>df</td>\n",
       "      <td>benign</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  mel  nv  bcc  akiec  bkl  df  vasc lesion diagnosis  benign  \\\n",
       "0  DERM_001    0   0    0      0    0   1     0     df    benign       1   \n",
       "1  DERM_002    0   0    0      0    0   1     0     df    benign       1   \n",
       "2  DERM_003    0   0    0      0    0   1     0     df    benign       1   \n",
       "3  DERM_004    0   0    0      0    0   1     0     df    benign       1   \n",
       "4  DERM_005    0   0    0      0    0   1     0     df    benign       1   \n",
       "\n",
       "   malignant  precancerous  \n",
       "0          0             0  \n",
       "1          0             0  \n",
       "2          0             0  \n",
       "3          0             0  \n",
       "4          0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac16deb7e2094aad9d80fc59b5e91984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10276.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#preprocessed images download link: https://bit.ly/processed_image\n",
    "\n",
    "#loading preprocessed image data\n",
    "all_images = []\n",
    "#tdqm: states current status of image loading process\n",
    "for i in tqdm_notebook(range(all_labels['image'].shape[0])):\n",
    "    \n",
    "    #load in images with size 284 x 284\n",
    "    img = image.load_img('../datasets/processed_image/' + all_labels['image'][i] + '.jpg', \n",
    "                         target_size=(284,284))\n",
    "    img_array = image.img_to_array(img) \n",
    "    img = img_array/255 #divide by 255 for rescaling\n",
    "    all_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make image data into an array\n",
    "X = np.array(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10276, 284, 284, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of columns to be excluded from target variables y\n",
    "columns_dropped = [x for x in all_labels.columns if x not in ['benign', 'malignant', 'precancerous']]\n",
    "\n",
    "#create y that contains all 3 target variables/classes\n",
    "y = np.array(all_labels.drop(columns= columns_dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10276, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we will be doing a 20-80 train-test split, followed by a 25-75 train-validation split.\n",
    "This means that our X and y data will be splited into train, validation and test sets with a ratio of 20-20-60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split for train and test sets\n",
    "#20/80 split with random state of 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dataset:  (8220, 284, 284, 3)\n",
      "y_train dataset:  (8220, 3)\n",
      "X_test dataset:  (2056, 284, 284, 3)\n",
      "y_test dataset:  (2056, 3)\n"
     ]
    }
   ],
   "source": [
    "#check for shape of train and test datasets\n",
    "print(\"X_train dataset: \", X_train.shape)\n",
    "print(\"y_train dataset: \", y_train.shape)\n",
    "print(\"X_test dataset: \", X_test.shape)\n",
    "print(\"y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train validation split for train and validation sets\n",
    "#25/75 split with random state of 42\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42, test_size = 0.25, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dataset:  (6165, 284, 284, 3)\n",
      "y_train dataset:  (6165, 3)\n",
      "X_val dataset:  (2055, 284, 284, 3)\n",
      "y_val dataset:  (2055, 3)\n"
     ]
    }
   ],
   "source": [
    "#check for shape of train and validation datasets\n",
    "print(\"X_train dataset: \", X_train.shape)\n",
    "print(\"y_train dataset: \", y_train.shape)\n",
    "print(\"X_val dataset: \", X_val.shape)\n",
    "print(\"y_val dataset: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to reshape X_train from shape (a,b,c,d) into (a,b) for SMOTE\n",
    "X_train = X_train.reshape(6165, 284 * 284 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6165, 241968)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise SMOTE, with knn of 3\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "\n",
    "#fit and resample on X_train, y_train\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12240, 241968)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12240, 284, 284, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape back to initial shape of (a,b,c,d)\n",
    "X_smote = X_smote.reshape(12240, 284, 284, 3)\n",
    "X_smote.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving X_smote and y_smote\n",
    "np.save('../datasets/npy/diagnosis/X_smote_diagnosis_284.npy', X_smote)\n",
    "np.save('../datasets/npy/diagnosis/y_smote_diagnosis_284.npy', y_smote)\n",
    "\n",
    "#saving X_test and y_test\n",
    "np.save('../datasets/npy/diagnosis/X_test_diagnosis_284.npy', X_test)\n",
    "np.save('../datasets/npy/diagnosis/y_test_diagnosis_284.npy', y_test)\n",
    "\n",
    "#saving X_val and y_val\n",
    "np.save('../datasets/npy/diagnosis/X_val_diagnosis_284.npy', X_val)\n",
    "np.save('../datasets/npy/diagnosis/y_val_diagnosis_284.npy', y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
